# Deep-Reinforcement-Learning-under-Partial-Observability
This is a collection of research papers for Deep Reinforcement Learning algorithms under Partial Obsrvability.

Welcome to follow and star!

## Table of Contents

- [DRL under Partial Observability](#Deep-Reinforcement-Learning-under-Partial-Observability)
  - [Table of Contents](#Table-of-Contents)
  - [Overview of POMDP in RL](#overview-of-diffusion-model-in-rl)
  - [Papers](#papers)
  - [License](#license)

## Overview of PODMP in RL



## Papers

### papers

#### 2022 
- [Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs](https://arxiv.org/abs/2110.05038)
  - Tianwei Ni, Benjamin Eysenbach, Ruslan Salakhutdinov
  - Key：
  - Code： [Original Code Base](https://github.com/twni2016/pomdp-baselines)
  - ExpEnv: 
  - ICML 22 


- [Deep Transformer Q-Networks for Partially Observable Reinforcement Learning](https://arxiv.org/abs/2206.01078)
  - Kevin Esslinger, Robert Platt, Christopher Amato
  - Key: Transformer, DQN
  - Code: [Original Code Base](https://github.com/kevslinger/DTQN)
  - ExpEnv:

#### 2015
- [Deep Recurrent Q-Learning for Partially Observable MDPs](https://cdn.aaai.org/ocs/11673/11673-51288-1-PB.pdf)
  - Matthew Hausknecht and Peter Stone
  - Key: RNN, DQN
  - Code: 
  - ExpEnv: Atari
    
### benchmarks 



## License

Deep-Reinforcement-Learning-under-Partial-Observability is released under the Apache 2.0 license.
